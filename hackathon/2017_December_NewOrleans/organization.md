# Post hackathon recap

Overall the hackathon went well. There are several things that we might consider changing going forward but for a first time event it came off well. The real test is going to be how much continued engagement we get with the project moving forward.

## The good:
\+    Good peer interactions

\+    Excellent R/git introduction

\+    Good to have tasks at different levels

## The not so good:
\-    More engagement/set-up prior to event

\-    Directed paired programing with expert coders and novice data providers

\-    Clearer statements on what to expect and what is a hackathon

## Some quick numbers for the hackathon:
1 - data ingestion script! (Thanks Sam!)

2 - suggestions for changes to the infrastructure/features

3 - pull requests to https://github.com/ktoddbrown/soils-long-tail-recovery

7 - people contributed ‘Issues’ that either identified data or make suggestions to the repository

8 - hackathon related forks of https://github.com/ktoddbrown/soilDataR

14 - new data sets identified

23 - hackathon related forks of https://github.com/ktoddbrown/soils-long-tail-recovery

28 - people showed up for some part of the hackathon

30 - unique users on the repository day of the hackathon

33 - people signed up for hackathon

### Transcription of the feedback stickies from the end of the workshop
\-    Suggestion: divide into teams with data creators and software folks - suggest paired programming

\-    It would have been helpful to see a little walk through of the existing database so it was more visually apparent what the desired outcome was ahead of time

\-    Maybe some more pre-interaction between people could help to work better

\-    Get people started faster. Maybe pre-hack organization

\-    A little more instruction of outcome possibilities (it took us a while to figure out what to do and how to get started

\-    Too many newbies, too self directed should orgainziaze by tasks (so work together)

\-    Data vis and automation download prior to work would help

\+    Pushed me to start

\+    Quick intro to R/Git

\+    Learned about tidyverse - thanks!

\+    Thank you! This was a great idea/execution

\+    Great job facilitating and having tasks for people at different levels

\+    Good table interaction

\+    Good networking, a lot of experience and knowledge

\+    Really interesting meeting and very useful

\+    Awesome thanks for bringing us together!

### Post-workshop survey:
https://goo.gl/forms/SE8x9n8xveOeYVYo1

| Time stamp | I learned or was motivated to learn new things about git that I didn't know before the hackathon. Before the workshop I couldn't do this but now I can now figure out how to... | I learned or was motivated to learn new things about R that I didn't know before the hackathon. Before the workshop I couldn't do this but now I can now figure out how to... | During the hackathon, I found out how to | Are there any other things you want to tell us? |
| --- | --- | --- | --- | --- |
| 12/21/2017 16:01:44 | | use the tidyverse family of libraries | identify datasets of interest for the project, contribute scripts for data ingestion | |
| 12/22/2017 11:19:37 | explain what git is! | | | While I appreciate the effort of what you did, I feel that there needed to be some more direction, especially for people who didn't have tasks in mind. (My goal was to start working on writing a script for entering my data.) I feel that people would have been better served by being divided into groups (writing scripts to get own data into R, find data, writing scripts to do stuff with data). That way people could help each other and those without a firm task could help with those who had direction. |
| 12/30/2017 20:19:02 | clone a remote repository, fork and pull someone else's repository | | explain the ISCN soil data recovery and harmonization project | It would have been useful to have more specific objectives outlined for participants who came in without a known dataset to work on. |

### Pre-workshop survey:
https://goo.gl/forms/h07viuSRdTMICXe23

The complete survey is in this folder but here is a summary of the knowledge base of the participants:

|     | Yes   | No |
| --- | --- | ---|
| Git: Do you know what git is?                                                                    | 12  |1 |
| Git: Have you ever added and committed changes to a git repository?   | 6  | 7 |
| Git: Have you ever cloned a remote repository?                                      | 5 | 8 |
| Git: Have you ever forked a repository and submitted a pull request?    |6 | 7 |
| Git: Have you ever resolved a merge conflict?                                         | 5 | 8 |
| R: Have you ever read in a csv file?                                                          | 13 | 0 |
| R: Have you ever made a graph in R?                                                       | 13 | 0 |
| R: Have you ever written an R function?                                                     | 11 | 2 |
| R: Have you ever written a Rmarkdown document?                                   |6| 7 |
| R: Have you ever used the tidyverse family of libraries (including ggplot2, dplyr, broom, and/or tidyr)? |11| 2 |
| R: Have you submitted a package to CRAN or otherwise maintained an R-package? | 1 | 12 |

## Final email sent out Thursday 21 December 2017
Dear data hacker,

I hope that your AGU was productive and that you got to try some of the amazing food that was in New Orleans! I would like to thank you for participating in the first hackathon for the ISCN soil carbon data recovery and harmonization project.

We have a quick follow up survey that we would like to ask you to fill out here so we can gauge the impact of the hackathon: https://goo.gl/forms/mvigVuZHpZl98CO43

Some quick numbers for the hackathon:

1 - data ingestion script! (Thanks Sam!)

2 - suggestions for changes to the infrastructure/features

3 - pull requests to https://github.com/ktoddbrown/soils-long-tail-recovery

7 - people contributed ‘Issues’ that either identified data or make suggestions to the repository

8 - hackathon related forks of https://github.com/ktoddbrown/soilDataR

14 - new data sets identified

23 - hackathon related forks of https://github.com/ktoddbrown/soils-long-tail-recovery

30 - unique users on the repository day of the hackathon

You can stay involved with the project at a number of levels:
1)    Watch the repository for new issues and changes via the ‘watch’ button on the GitHub repositories ( https://help.github.com/articles/watching-and-unwatching-repositories/ )
2)    Continue to contribute to the repositories by identifying data, writing ingestions/output scripts or otherwise pushing fun and interesting stuff to the repositories! (Don’t forget to add yourself to the CONTRIBUTORS.txt document.)
3)    Join the ISCN mailing list
4)    Set up an ISCN hackathon at your institution
5)    Email (iscncoordinator@gmail.com) if you are interested in becoming a Scientific Lead and organize the finding/ingest data on a particular topic
6)    Email (iscncoordinator@gmail.com) if you are interested in becoming an Infrastructure Lead and organize expansion of the functionality of the base code

It was a pleasure meeting all of you. We had lots of feedback that the peer interaction was the best part of the hackathon; well done everyone!

If you have any questions, or comments please don’t hesitate to get in touch.
-Kathe Todd-Brown & the ISCN team


#Pre-hackathon
Shopping list:
+ Badges -AM done
+ Small-medium sized colored dots (minimum 3 colors) -KTB ToDo
+ Sticky notes (flag helpers & brainstorming) -KTB done
+ Push pins (incase we are dealing with divider walls that don’t take stickies) -KTB done

When people arrive have
1)    name + home institute tag
2)    2nd name tag with primary research interest [2? word limit]
3)    Color dot stickers for R (blue) & git (green) helpers & data generators (yellow)
4)    Check they have R and git setup, recruit folks as needed to help with this
5)    Sticky note votes for topical groups
a)    Give everyone one sticky note and have them write what topic/data type they would be interested in. Seed with a couple of example options in an off color so they can be separated out. Post on a wall next to the food/drink or somewhere folks are motivated to interact with.
b)    Topic group seeds: laboratory incubation data, survey data, field manipulation data, QA/QC scripts, temperature sensitivity, moisture sensitivity, fractionation data, isotope data, registering data with a repository

Schedule (post schedule near food with snarky comment about it changing without notice)
+ 12:00pm - Get everyone tagged/dotted (names, interests, expertise) and generate topic groups
  - check that everyone is set up with R and git
+ 1:00 pm - Introduction and ice breakers
+ 1:30 pm - Break out into groups around topic area and fork repository
+ 2:00 pm - Hack!
+ 4:30 pm - Commit, submit pull requests, start issues
+ 4:45 pm - Sticky note feedback, how to stay involved, schedule coffee/drinks to continue working at AGU(?) and other follow up activities like regular video meetings.

References:
+ An interesting take on an unConference: https://ropensci.org/blog/2017/11/17/unconf-sixtips/
+ 10 simple rules for an unConverence: http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003905
+ Icebreaker (taking a stand)
+ https://www.facinghistory.org/resource-library/teaching-strategies/barometer-taking-stand-controversial-issues


Lessons learned:
1)    Set up some way for attendees to engage with project and each other prior to event.

## Emails pre hackathon

Subject: ISCN hackathon welcome

Sent: 1145AM Monday 20 November 2017

TO WaitList: Thank you for your interest in the ISCN hackathon scheduled for December. Right now this is to confirm that you are on the waitlist for this event, but we are anticipating a few slots will open in in the next few weeks. To keep you in the loop, below is an email that went out about the event. I would also like to invite you to participate in the project remotely whenever is convenient to you by contributing to the project repository and discussion described below and invite you to take the survey about your interest and skills even if you aren’t sure you’ll be at the event. )

Dear data hackers,

I’m excited to welcome you to the first International Soil Carbon Network (ISCN) hackathon. The main purpose of this hackathon is to identify, harmonize, and compile data sets related to soil carbon dynamics, most of you are either data providers, R experts, or otherwise interested in soil carbon data. This is the first of a series of emails to help get you set up for the hackathon so we can squeeze the most out of this 4 hour event.

First, we have a few people on the waitlist. If you are not able to make it for whatever reason please let us know! Also there is an ISCN All Hands meeting Sunday morning (agenda forthcoming) which you are strongly encouraged to attend as well (sign up here: https://docs.google.com/forms/d/e/1FAIpQLSc423-Ci6b2if2fXfQ9YDak2A4sM3lftPFMNTDpkbXKDjqYPA/viewform )

For the hackathon, we’ll be working off of the new ISCN data ingestion repositories. The primary repository is here: https://github.com/ktoddbrown/soils-long-tail-recovery with a supporting R package you can find here: https://github.com/ktoddbrown/soilDataR There are three main ways to contribute to the project: identify data, data processing, and QA/QC. The hackathon will focus primarily on data processing but please feel free to branch out before or after the event!

Data providers: if you have data you are bringing great! Please archive it with an online repository like http://datadryad.org/,  https://www.pangaea.de/, or an institutional library.

Everyone: If you don’t have a GitHub account, now is a good time to get one. We are using https://github.com/ktoddbrown/soils-long-tail-recovery/issues to track both possible data sets, discuss improvements to the underlying code base, and generally talk about the project. Please feel free to start or contribute to the discussion there. We are looking to better gauge everyone’s R and git background so we can provide the right introduction, please fill out this form by Sunday 26 November 2017: https://goo.gl/forms/CGJoNup3y1Wdtkzp1 to give us a better idea of where everyone is at!

I’ll send out another email next week talking a little bit about the technical details of the project.

Looking forward to meeting everyone in the Big Easy!

Kathe Todd-Brown

ISCN co-coordinator
==================================

Sent: 1144AM Monday 27 November 2017

Subject: ISCN hackathon project structure

Dear data hackers,

I’m glad that you can make it to the ISCN Hackathon next month in New Orleans. We were able to move those on the waitlist to attendee list, so a special welcome to those of you who were on the waitlist. If you can not make the hackathon please let us know so we can have a headcount for the event. I thought I would give you a quick reminder of some prep work for the hackathon and share with you some of the logic behind this project.

At this point you should have a github account (https://github.com/) and I hope you’ve been able to check out the repository that we’ll be working with: https://github.com/ktoddbrown/soils-long-tail-recovery. If you are bringing data with you please be sure to upload it to an online archive such as http://datadryad.org/,  https://www.pangaea.de/, or an institutional library. If you have not already done so, please fill out the pre-hackathon survey so we know what background to present at the hackathon: https://goo.gl/forms/rbyiISLbB0aMv4r42

ISCN evolved out of a need for large scale data synthesis in soils to extract broad trends for soil management and to better understand the carbon cycle. The “ISCN3” database includes layer or horizon-level data from several dozen different data providers (mostly soil surveys) across the world. This version was driven by a Microsoft SQL Server and maintained by a small group of programmers adding new data or expanding variables as time allowed. We are looking to transform this into an open source community project and expand from soil survey data to experimental data in order to focus on a number of emerging needs; thus this hackathon to kick off this new phase. We have a base vocabulary developed for ISCN3 (see below) that we are going to build off of for future versions. Future data products will continue to include data ingested for ISCN3 but will also include new contributions where data reuse permissions permit. These future data products will be built using the code repository (https://github.com/ktoddbrown/soils-long-tail-recovery and https://github.com/ktoddbrown/soilDataR ) that can also be used independently of any data product to harmonize targetted data sets.

The ISCN3, Treat, and Alamos datasets are not necessary for the hackathon but they do provide a broader context for your samples and examples for your own data ingestion scripts.
ISCN3 is available at http://iscn.fluxdata.org/data/access-data/database-reports/. You’ll need to fill out a quick registration form for access if you haven’t done so already. While you are there you can also download the data that was prepped for ISCN4, which includes the Treat peatland and Alamos data sets already scripted for data ingestion as examples in https://github.com/ktoddbrown/soils-long-tail-recovery/blob/master/reports/2016DataVisulize.Rmd

How do you write a data ingestion script? One way is to use a genetic function and key approach. This key must identify:

+    header - name of each column,
+    dataframe - where each column belongs, var- which refers to the ISCN standard variable name,
+    class - what kind of data is in the column (numeric, factor, character),
+    type - if the columns are being converted to long format, what type of data is this (value, sigma, method, unit),
+    hardUnit - if the unit is not identified by another column, what is the unit.
A good example of a key is the one developed for the Powell Center soil fractionation project in soils-long-tail-recovery/dataset-key/PowellCenterKey.xlsx This is then used to key a set of excel spreadsheets and convert them to an internal data representation.

Alternatively, a custom script can be crafted for the dataset. ISCN3 was a custom script due to it’s large size but any particularly unique format could also be customized. This script can be found here if you are interested https://github.com/ktoddbrown/soilDataR/blob/master/R/processData_ISCN3.R

Internally, the structure of the data a little in flux, however it is converging on 5 relational tables:
+    study - information about the study including citation and data use policy,
+    field - information about the geospatial-temporal site that the sample was taken from,
+    treatment - any experimental treatment applied to the site or samples,
+    measure - a description of the measurements taken, and
+    samples - the actual values taken from a soil sample.
Currently measure and samples are the only long-format tables with defined headers for the sample (studyID, fieldID, treatmentID, measureID, value, sigma), measure (measureID, var, method, unit). There is a toy example walk through at the repository wiki-page here: https://github.com/ktoddbrown/soils-long-tail-recovery/wiki

We’ll go over this again at the hackathon, but if you have any suggestions or want to get involved with the project a bit sooner please feel free to post to the forum https://github.com/ktoddbrown/soils-long-tail-recovery/issues or submit a “pull request”. More information on forking repositories and submitting pull requests can be found here: https://help.github.com/categories/collaborating-with-issues-and-pull-requests/

I’ll be in touch again next week to talk about meeting logistics and go into a bit more detail on how contributions will be structured for the hackathon. If you have any questions please get in touch with me.

I hope everyone in the US had a good Thanksgiving,

Kathe Todd-Brown

ISCN co-coordinator

====================================

Sent: 15:15 PM PT Monday 4 December 2017

Subject: ISCN hackathon helpers

Dear data hackers,

I would like to invite you to identify as ‘helpers’ during the hackathon. You don’t have to be an expert but we are looking for people who are willing to help with both git and R. In particular, I anticipate we’ll be looking for people to help with:
1)    Forking and cloning the main GitHub repositories
2)    Submitting pull requests
3)    Programming expertise

Everyone at the hackathon has some basic knowledge of how to interact with datasets in R but in some cases it’s limited, and this will be the first time using forks and pull requests for many of the attendees. Your experience would be invaluable to your less experienced colleagues.

What does being a helper mean? First we’ll ask you to identify yourself as a git and/or R ‘helper’ when you check in (likely with a colorful sticker on your name badge). Then after a brief introduction we’re going to break into smaller groups clustered around common topics. We are hoping for at least one helper per topic group to answer questions about git and help folks with various coding hurdles they face.

Being a helper could also be ideal for you if you are not bringing data and feel you don’t have a targeted topic interest. Or we are also looking for people to write output scripts and work on QA/QC.

Please let me know by Dec 6 if you would consider being a helper for the hackathon or particularly interested in output scripting and QA/QC.

Regardless of what you choose to do I’m looking forward to seeing you at the hackathon next week!
-Kathe Todd-Brown
ISCN co-coordinator


====================================

Subject: ISCN hackathon logistics

Date: Dec 4, 2017, 3:47 PM

Dear data hackers,

Hard to believe that AGU is next week! Here are some last minute logistical details for the hackathon, a quick checklist to make sure your ‘homework’ is done before the hackathon, and some more information on how the main repositories are structured.

The hackathon is at 12PM-5PM in Galerie 3 (second floor), Marriott New Orleans, 555 Canal st., New Orleans, LA. Lunch will be provided. Everyone is encouraged to attend the ISCN all-hand meeting in the morning (8AM-12PM) and you can still sign up here: http://iscn.fluxdata.org/2017/07/24/agu2017/ Please bring your laptop and any data that you want to work on during the hackathon. Below is the basic schedule:
+ 12-1pm: Lunch with check in, git and R set up, submit data to repositories and identify topic specific working groups
+ 1-1:30pm: Introductions and icebreakers
+ 1:30-2pm: Fork the main repositories
+ 2-4:30pm: Data hacking!
+ 4:30-5pm: Feedback and what’s next

If you would like help setting up git, R, registering data or otherwise have logistical questions PLEASE be sure to come at 12pm so we can get everyone orientated before the main event. I’m also happy to respond to emails before Saturday to help people set up.

At this point everyone should have a GitHub account, taken a look at the main repository: https://github.com/ktoddbrown/soils-long-tail-recovery and, hopefully, deposited any data you are bringing to an online repository. If you’ve never worked with git before here are some good introduction: https://guides.github.com/introduction/git-handbook/ and http://swcarpentry.github.io/git-novice/.   If you have never worked with a community repository before, now might be a good time to take a quick look at forking a repository https://help.github.com/articles/fork-a-repo/ and creating a pull request https://help.github.com/articles/about-pull-requests/.

I spoke a little about data ingestion last week, we currently have two main ways to ingest data. The first is a key-worksheet format where a key is developed for each dataset and then fed into a generic function. The second is a fully customized function, and is generally used for large datasets or datasets with unusual structures.

Data ingestion is of course just one part of the process we still need to aggregate that data. Once the data has been converted to a common vocabulary in the ingestion, we convert any units that do not match, perform QA/QC, and use row bind to glue the internal data frames together. This haromonized dataset is then passed to output scripts which produce the final data product. Right now this data aggregation is done in a markdown document https://github.com/ktoddbrown/soils-long-tail-recovery/blob/master/reports/2016DataVisulize.Rmd but before each benchmark we will convert this into a processing script that will harmonize the new data ingested for that version. For the hackathon, we’ll create a special folder with these data ingestion scripts and pointers to where you can access the data sets.

As the database evolves there will be times when a measurement or site characteristic is recorded in the dataset but not in the core ISCN vocabulary. Great! This is an opportunity to discuss expanding the database with the broader ISCN community. New variables can be presented as candidates and changes to control vocabulary suggested in an ongoing fashion.

I wish everyone smooth travels and looking forward to seeing you next week!

Kathe Todd-Brown


