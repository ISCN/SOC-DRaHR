---
title: "Data from C-PEAT"
author: "C-PEAT and Texas A&M Hackers"
date: "5/7/2018"
output: 
  html_document: 
    toc: yes
---

```{r setup}
library(tidyverse)
```

```{r eval=FALSE}
library(googledrive)
##pull all the files that we are working with for the hacakthon from the google drive
file.ls <- drive_ls(path='Professional/Data Hackathon TAMU 2018')
cat(sprintf('# %s \n\n', sort(file.ls$name)))
```

# Start here

1) Fork the main repository https://github.com/ISCN/SOC-DRaHR
2) Start by going to the master file and claiming a data file to work on. https://docs.google.com/spreadsheets/d/1hXyCW5TkLrt7en7tcz43lWHPxl5vVtG9qlkcr6t3zBs/edit?usp=sharing
3) Download your claimed data file from the google drive to a tempoary directory that you DO NOT commit to the repository https://drive.google.com/open?id=1k7CwjDePBuounwCMU1UFcWEsBlvwReWt
    - Do not commit data to the repository. The pull request will be denied.
4) Hack!
    1) Read in each table on the sheet
    2) If data is a soil measurement convert to a long table, otherwise keep wide
        - make sure entries are cross referenced and try to use informative unique ids
    3) Convert soil depth to top/bottom depth
    4) Convert to ISCN naming scheme and seperate units; see CPEAT_key.csv
    5) Plot data in histograms and map lat/lon; eyeball to make sure everything looks right
5) Add to your local git repository and push to your remote repository
6) Submit a pull request to the main repository
7) Claim your contributor status!
8) Repeat 1-6 until no data left

Remember to:

1) Steal shamelessly and credit generously.
2) Ask Google; then ask your neighbor; then ask an 'expert'.
3) Celebrate new and interesting mistakes.
4) There is ALWAYS more then one way to do something.
5) Document your code like you're passing it onto a dear friend to maintain.

## Useful notes
Any useful notes you find can go here for now: https://docs.google.com/document/d/1WeqesuFO--5AhQHQywNzdYSIoR9dctklhLjmCZy1chk/edit?usp=sharing
They will be transcribed to this document after the hackathon.

# Data ingest scripts

## 86-Kvartal.csv 
```{r 86-Kvartal}
dataFile <- '~/CPEAT_workshop/86-Kvartal.csv' #file path of data 
allData <- read_csv(file=dataFile, skip=1) #big data table of everything

metaData <- allData[,1:2] %>% #read first two columns as metadata
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #remove empty rows
  bind_rows(tibble(site_name='site_name', `86-Kvartal`='86-Kvartal')) %>% #transfers misidentified headers to data table
  spread(key=site_name, value='86-Kvartal') #convert table from long to wide

sampleData01 <- allData[ ,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long format exclude columns that are characters not numerics
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value)) #remove missing values
  sampleData <- sampleData01 %>%
  bind_rows(sampleData02) #combine with previous samples
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

#mapping libraries to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- borders("world", colour="gray80", fill="gray80") # create a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  mapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw() +
  theme(text=element_text(size=18),
        axis.title=element_blank())  
```

## Aero.csv 

## Altay.csv 
```{r Altay}
dataFile <- '~/CPEAT_workshop/Altay.csv' #file path of data 
allData <- read_csv(file=dataFile, skip=1) #big data table of everything

metaData <- allData[,1:2] %>% #read first two columns as metadata
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #remove empty rows
  bind_rows(data.frame(site_name='site_name', Altay='Altay')) %>% #transfers misidentified headers to data table
  spread(key=site_name, value=Altay) #convert table from long to wide

sampleData01 <- allData[ ,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long format exclude columns that are characters not numerics
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value)) #remove missing values
  sampleData <- sampleData01 %>%
  bind_rows(sampleData02) #combine with previous samples
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

#mapping libraries to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- borders("world", colour="gray80", fill="gray80") # create a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  mapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw() +
  theme(text=element_text(size=18),
        axis.title=element_blank())  
```

## Bear.csv 

## Burnt_Village.csv 

```{r Burnt_village}

dataFile <- 'C:/Users/Kritika/Documents/Hackathon/Burnt_Village.csv' #data location on your computer

allData <- read_csv(file=dataFile, skip =1) #big data table of everything!

metaData <- allData[,1:2] %>% #first two columns at meta data
  filter(!is.na(site_name) ) %>% #remove empty rows
  bind_rows(data.frame(site_name='site_name', Burnt_Village='Burnt_Village' )) %>% #transfers miss-identified headers to data table
  spread(key=site_name, value = Burnt_Village) #convert long to wide

sampleData01 <- allData[ ,5:14] %>% #identify columns for sample reads
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long format excludes columns that are characters not numerics
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value))

sampleData <- sampleData01
  bind_rows(sampleData02) #combine this with previous sample
  
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales='free')


#mapping librarys to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- ggplot2::borders("world", colour='gray80', fill='gray80') #create a layer of borders

ggplot()+mapWorld

ggplot(metaData %>%
         mutate_at(vars(latitude,longitude), as.numeric))+
  mapWorld+
  geom_point(aes(x=longitude, y = latitude)) +
  theme_bw()+ 
  theme(text=element_text(size=18), axis.title=element_blank())

```

## Covey_Hill.csv 

## D127.csv 

## E110.csv 

## Ennadai.csv 

## Glen_Carron.csv 

## Glen_Torridon.csv 

## Goldeye.csv 

## HL02.csv 

## Hongyuan.csv 

## Horse_Trail.csv 

## JBL1.csv 

## JBL2.csv 

## JBL3.csv 

## JBL4.csv 

## JBL5.csv 

## JBL7.csv 

## JBL8.csv 

## Joey.csv 

## KAM12-C1.csv 

## KAM12-C4.csv 

## Kenai_Gasfield.csv 

## KJ2-3.csv 

## KUJU.csv 

## La_Grande2.csv 

## La_Grande3.csv 

## Lac_Le_Caron.csv 

## Lake396.csv 

## Lake785.csv 

## Lebel.csv 

## Lompolojankka.csv 
```{r Lompolojankka}


dataFile <- '~/Documents/Git_Workshop/SOC-DRaHR/hackathon/2018_May_CollegeStation_TX/Workshop/Lompolojankka.csv'
allData <- read_csv(file = dataFile, skip=1)
metaData <- allData[,1:2] %>%
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>%
  bind_rows(data.frame(site_name="site_name", Lompoloj_nkk_="Lompolojankka",
                       stringsAsFactors = FALSE)) %>%
  spread(key=site_name, value=Lompoloj_nkk_)

sampleData <- allData[,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  mutate(value=as.numeric(value))

sampleData <- allData[,17:23] %>%
  rename(header="date_type", value='uncal_date_BP', depth='depth_cm') %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  bind_rows(sampleData)
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

MapWorld <- ggplot2::borders("world", colour = "gray80", fill = "grey80") #creating a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  MapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_light()
theme(text=element_text(size=18),
      axis.title=element_blank())
         

```
## Mariana.csv 

## Martin.csv 
```{r Martin}
datafile <- "~/Documents/R_Studio/C-PEAT/Martin.csv" #data location on local machine
allData <- read_csv(file = datafile, skip = 1) #giant data table of everything
metaData <- allData[,1:2] %>% #read first two columns as metadata
  filter(!is.na(site_name) & !grepl("^\\s*$", site_name)) %>% #remove empty rows
  bind_rows(data.frame(site_name = "site_name", Martin = "Martin", 
                       stringsAsFactors = FALSE)) %>% #transfers misidentified 
                                                      #...headers to data table
  spread(key = site_name, value = Martin) #convert long data to wide format

#
sampleData <- allData[,5:14] %>% #identify columns for sample reads
  gather(key = "header", value = "value", -depth) %>% #convert to long format
                                        #...format, exclude columns that 
                                        #...are characters (not numeric)
  filter(!is.na(value) & !grepl("^\\s*$", value)) %>% #remove missing values
  mutate(value = as.numeric(value)) #make sure values are numerics

sampleData <- allData[,17:23] %>% #identify columns for sample reads
  rename(header = "date_type", value = "uncal_date_BP", depth = "depth_cm") %>% #harmonize
                                            #...headernames to match previous samples
  filter(!is.na(value) & !grepl("^\\s*$", value)) %>% #remove missing values
  bind_rows(sampleData) #combine this with previous sample data table

#mapping librarys to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- ggplot2::borders("world", colour = "gray80", fill = "gray90")
        #create a border of the layers
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
          #change the lat and long from character to numeric
  mapWorld +
  geom_point(aes(x=longitude, y=latitude), color = "red", size = 3) +
  theme_classic() +
  theme(text = element_text(size=18),
                axis.title=element_blank())

mapWorld <- borders("world", colour = "gray80", fill = "gray90")

```


```{r Martin}

dataFile <- '~/Documents/Git_Workshop/SOC-DRaHR/hackathon/2018_May_CollegeStation_TX/Workshop/Martin.csv' #Data location on the computer
allData <- read_csv(file = dataFile, skip=1) #Creates a big data table
metaData <- allData[,1:2] %>% #Read in first two columns as metadata
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #Removes rows that have site_name & blanks
  bind_rows(data.frame(site_name="site_name", Martin="Martin", #makes a new dataframe
                       stringsAsFactors = FALSE)) %>%          #adds headers to the dataframe
  spread(key = site_name, value = Martin) #convert long to wide
  sampleData <- allData[,5:15] %>% #identifies columns for sample reads
    gather(key='header', value='value', -depth, -peat_type) %>% #convert wide to long format                                                              and excludes the selected columns
    filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #removes missing values
    mutate(value=as.numeric(value)) #make sure the values are numberic
  
sampleData <- allData[,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize headers
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%                                               #to match prev.
  bind_rows(sampleData) #combines this with previous samples

#Creates a histogram of the plot
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free') #creates subplots, has to be the same type of plot

#Visualization of site
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

MapWorld <- ggplot2::borders("world", colour = "gray80", fill = "grey80") #creating a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  MapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw()
theme(text=element_text(size=18),
      axis.title=element_blank())

```

## Mosaik.csv 
```{r Mosaik}
dataFile <- '~/CPEAT_workshop/Mosaik.csv' #file path of data 
allData <- read_csv(file=dataFile, skip=1) #big data table of everything

metaData <- allData[,1:2] %>% #read first two columns as metadata
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #remove empty rows
  bind_rows(data.frame(site_name='site_name', Mosaik='Mosaik'))   %>% #transfers misidentified headers to data table
  spread(key=site_name, value=Mosaik) #convert table from long to wide

sampleData01 <- allData[ ,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long format exclude columns that are characters not numerics
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value)) #remove missing values
  sampleData <- sampleData01 %>%
  bind_rows(sampleData02) #combine with previous samples

ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

#mapping libraries to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- borders("world", colour="gray80", fill="gray80") # create a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  mapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw() +
  theme(text=element_text(size=18),
        axis.title = element_blank())
```

```{r Mosaik}
dataFile <- '~/Documents/Datasets/CPEAT/Mosaik.csv' #data location on your computer

allData <- read_csv(file=dataFile, skip=1) #big data table of everything!

metaData <- allData[,1:2] %>% #read first two columns as meta data
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #remove empty rows
  bind_rows(data.frame(site_name='site_name', Mosaik='Mosaik',
                       stringsAsFactors=FALSE)) %>% #transfers miss-identified
                                                    #...headers to data table
  spread(key=site_name, value=Mosaik) #convert long to wide

#zero is the surface, 1 is the 
sampleData01 <- allData[ ,5:14] %>% #identify columns for sample reads
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long
                    #...format exclude columns that are characters not numerics
  filter(!is.na(value) & ! grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics
  

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>%
                              #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value))
  
sampleData <- sampleData01 %>%
  bind_rows(sampleData02) #combine this with pervious samples

ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales='free')

#mapping librarys to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- ggplot2::borders("world", 
                             colour='gray80', fill='gray80')# create a layer of borders

ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  mapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw() +
  theme(text=element_text(size=18),
        axis.title=element_blank())
```

## No_Name_Creek.csv 

## Nuikluk.csv 

## NW-BG.csv 

## Ours.csv 

## Patuanak.csv 

## Petersville.csv 

## Petite_Bog.csv 

## Plaine.csv 

## Rogovaya.csv
```{r Rogovaya}

##Core One

dataFile <- '~/Documents/Git_Workshop/SOC-DRaHR/hackathon/2018_May_CollegeStation_TX/Workshop/Rogovaya.csv'
allData <- read_csv(file = dataFile, skip=1)
metaData_Core1 <- allData[,1:2] %>%
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>%
  bind_rows(data.frame(site_name="site_name", Rogovaya="Rogovaya",
                       stringsAsFactors = FALSE)) %>%
  spread(key=site_name, value=Rogovaya)

sampleData_Core1 <- allData[,6:15] %>%
  gather(key='header', value='value', -depth, -peat_type) %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  mutate(value=as.numeric(value))

sampleData_Core1 <- allData[,18:24] %>%
  rename(header="date_type", value='uncal_date_BP', depth='depth_cm') %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  bind_rows(sampleData_Core1)
  
ggplot(sampleData_Core1) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

MapWorld <- ggplot2::borders("world", colour = "gray80", fill = "grey80") #creating a layer of borders
ggplot(metaData_Core1 %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  MapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_light()
theme(text=element_text(size=18),
      axis.title=element_blank())
         
##Core Two

metaData_Core2 <- allData[,c(1,3)] %>%
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>%
  bind_rows(data.frame(site_name="site_name", Rogovaya_1="Rogovaya_1",
                       stringsAsFactors = FALSE)) %>%
  spread(key=site_name, value=Rogovaya_1)

sampleData_Core2 <- allData[,27:36] %>%
  gather(key='header', value='value', -depth_1, -peat_type_1) %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  mutate(value=as.numeric(value))

sampleData_Core2 <- allData[,39:45] %>%
  rename(header="date_type_1", value='uncal_date_BP_1', depth='depth_cm_1') %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  bind_rows(sampleData_Core2)

ggplot(sampleData_Core2) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

MapWorld_Core2 <- ggplot2::borders("world", colour = "gray80", fill = "grey80") #creating a layer of borders
ggplot(metaData_Core2 %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  MapWorld_Core2 +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_light()
theme(text=element_text(size=18),
      axis.title=element_blank())

```

## Saarisuo.csv 

## Selwyn.csv 
```{r Selwyn}


dataFile <- '~/Documents/Git_Workshop/SOC-DRaHR/hackathon/2018_May_CollegeStation_TX/Workshop/Selwyn.csv'
allData <- read_csv(file = dataFile, skip=1)
metaData <- allData[,1:2] %>%
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>%
  bind_rows(data.frame(site_name="site_name", Selwyn="Selwyn",
                       stringsAsFactors = FALSE)) %>%
  spread(key=site_name, value=Selwyn)

sampleData <- allData[,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  mutate(value=as.numeric(value))

sampleData <- allData[,17:23] %>%
  rename(header="date_type", value='uncal_date_BP', depth='depth_cm') %>%
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>%
  bind_rows(sampleData)
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

MapWorld <- ggplot2::borders("world", colour = "gray80", fill = "grey80") #creating a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  MapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_light()
theme(text=element_text(size=18),
      axis.title=element_blank())
         

```

## Shuttle.csv 

## SIB06.csv 

## Sidney.csv 

## Siikaneva.csv 

## Slave.csv 

## Sterne.csv 

## Stordalen.csv 
```{r Stordalen}
dataFile <- '~/CPEAT_workshop/Stordalen.csv' #file path of data 
allData <- read_csv(file=dataFile, skip=1) #big data table of everything

metaData <- allData[,1:2] %>% #read first two columns as metadata
  filter(!is.na(site_name) & !grepl('^\\s*$', site_name)) %>% #remove empty rows
  bind_rows(data.frame(site_name='site_name', Stordalen='Stordalen'))   %>% #transfers misidentified headers to data table
  spread(key=site_name, value=Stordalen) #convert table from long to wide

sampleData01 <- allData[ ,5:14] %>%
  gather(key='header', value='value', -depth, -peat_type) %>% #convert to long format exclude columns that are characters not numerics
  filter(!is.na(value) & !grepl('^\\s*$', value)) %>% #remove missing values
  mutate(value=as.numeric(value)) #make sure values are numerics

sampleData02 <- allData[ ,17:23] %>% #identify columns for age
  rename(header='date_type', value='uncal_date_BP', depth='depth_cm') %>% #harmonize header names to match previous samples
  filter(!is.na(value) & !grepl('^\\s*$', value)) #remove missing values
  sampleData <- sampleData01 %>%
  bind_rows(sampleData02) #combine with previous samples
  
ggplot(sampleData) +
  geom_histogram(aes(x=value)) +
  facet_wrap(~header, scales = 'free')

#mapping libraries to help with global/regional plots
library(ggmap)
library(maps)
library(mapdata)
library(fiftystater)

mapWorld <- borders("world", colour="gray80", fill="gray80") # create a layer of borders
ggplot(metaData %>%
         mutate_at(vars(latitude, longitude), as.numeric)) + 
  mapWorld +
  geom_point(aes(x=longitude, y=latitude)) +
  theme_bw() +
  theme(text=element_text(size=18),
        axis.title=element_blank())  
```

## Sundance.csv 

## Swanson.csv 

## T1.csv 

## Unit.csv 

## Upper_Pinto.csv 

## Usinsk.csv 

## Utikuma.csv 

## V34.csv 

## Vasyugan.csv 

## VC04-06.csv 

## Zoige.csv